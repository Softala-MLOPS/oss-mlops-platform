{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Demo KFP pipeline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Install requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kfp~=1.8.14\n",
      "  Downloading kfp-1.8.22.tar.gz (304 kB)\n",
      "��━━━━━━━━━━\u001b[0m \u001b[32m304.9/304.9 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting absl-py<2,>=0.9 (from kfp~=1.8.14)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: PyYAML<7,>=5.3 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from kfp~=1.8.14) (6.0.2)\n",
      "Collecting google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 (from kfp~=1.8.14)\n",
      "  Downloading google_api_core-2.24.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting google-cloud-storage<3,>=1.20.0 (from kfp~=1.8.14)\n",
      "  Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl.metadata (9.1 kB)\n",
      "Collecting kubernetes<26,>=8.0.0 (from kfp~=1.8.14)\n",
      "  Downloading kubernetes-25.3.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting google-api-python-client<2,>=1.7.8 (from kfp~=1.8.14)\n",
      "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-auth<3,>=1.6.1 (from kfp~=1.8.14)\n",
      "  Downloading google_auth-2.38.0-py2.py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting requests-toolbelt<1,>=0.8.0 (from kfp~=1.8.14)\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting cloudpickle<3,>=2.0.0 (from kfp~=1.8.14)\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2 (from kfp~=1.8.14)\n",
      "  Downloading kfp-server-api-1.8.5.tar.gz (58 kB)\n",
      "��━━━━━━━━━━\u001b[0m \u001b[32m58.1/58.1 kB\u001b[0m \u001b[31m526.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: jsonschema<5,>=3.0.1 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from kfp~=1.8.14) (4.23.0)\n",
      "Collecting tabulate<1,>=0.8.6 (from kfp~=1.8.14)\n",
      "  Downloading tabulate-0.9.0-py3-none-any.whl.metadata (34 kB)\n",
      "Collecting click<9,>=7.1.2 (from kfp~=1.8.14)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting Deprecated<2,>=1.2.7 (from kfp~=1.8.14)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting strip-hints<1,>=0.1.8 (from kfp~=1.8.14)\n",
      "  Downloading strip_hints-0.1.13-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting docstring-parser<1,>=0.7.3 (from kfp~=1.8.14)\n",
      "  Downloading docstring_parser-0.16-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting kfp-pipeline-spec<0.2.0,>=0.1.16 (from kfp~=1.8.14)\n",
      "  Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl.metadata (323 bytes)\n",
      "Collecting fire<1,>=0.3.1 (from kfp~=1.8.14)\n",
      "  Downloading fire-0.7.0.tar.gz (87 kB)\n",
      "��━━━━━━━━━━━\u001b[0m \u001b[32m87.2/87.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting protobuf<4,>=3.13.0 (from kfp~=1.8.14)\n",
      "  Downloading protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting uritemplate<4,>=3.0.1 (from kfp~=1.8.14)\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting urllib3<2 (from kfp~=1.8.14)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "��━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "Collecting pydantic<2,>=1.8.2 (from kfp~=1.8.14)\n",
      "  Downloading pydantic-1.10.21-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (153 kB)\n",
      "��━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[?25hCollecting typer<1.0,>=0.3.2 (from kfp~=1.8.14)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting wrapt<2,>=1.10 (from Deprecated<2,>=1.2.7->kfp~=1.8.14)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting termcolor (from fire<1,>=0.3.1->kfp~=1.8.14)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp~=1.8.14)\n",
      "  Downloading googleapis_common_protos-1.68.0-py2.py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp~=1.8.14)\n",
      "  Downloading proto_plus-1.26.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp~=1.8.14) (2.32.3)\n",
      "Collecting httplib2<1dev,>=0.15.0 (from google-api-python-client<2,>=1.7.8->kfp~=1.8.14)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting google-auth-httplib2>=0.0.3 (from google-api-python-client<2,>=1.7.8->kfp~=1.8.14)\n",
      "  Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Requirement already satisfied: six<2dev,>=1.13.0 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from google-api-python-client<2,>=1.7.8->kfp~=1.8.14) (1.17.0)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.1->kfp~=1.8.14)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.1->kfp~=1.8.14)\n",
      "  Downloading pyasn1_modules-0.4.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.1->kfp~=1.8.14)\n",
      "  Downloading rsa-4.9-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-cloud-core<3.0dev,>=2.3.0 (from google-cloud-storage<3,>=1.20.0->kfp~=1.8.14)\n",
      "  Downloading google_cloud_core-2.4.2-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-resumable-media>=2.7.2 (from google-cloud-storage<3,>=1.20.0->kfp~=1.8.14)\n",
      "  Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-crc32c<2.0dev,>=1.0 (from google-cloud-storage<3,>=1.20.0->kfp~=1.8.14)\n",
      "  Downloading google_crc32c-1.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from jsonschema<5,>=3.0.1->kfp~=1.8.14) (25.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from jsonschema<5,>=3.0.1->kfp~=1.8.14) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from jsonschema<5,>=3.0.1->kfp~=1.8.14) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from jsonschema<5,>=3.0.1->kfp~=1.8.14) (0.22.3)\n",
      "Requirement already satisfied: certifi in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp~=1.8.14) (2025.1.31)\n",
      "Requirement already satisfied: python-dateutil in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from kfp-server-api<2.0.0,>=1.1.2->kfp~=1.8.14) (2.9.0.post0)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from kubernetes<26,>=8.0.0->kfp~=1.8.14) (75.8.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from kubernetes<26,>=8.0.0->kfp~=1.8.14) (1.8.0)\n",
      "Collecting requests-oauthlib (from kubernetes<26,>=8.0.0->kfp~=1.8.14)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from pydantic<2,>=1.8.2->kfp~=1.8.14) (4.12.2)\n",
      "Collecting wheel (from strip-hints<1,>=0.1.8->kfp~=1.8.14)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.3.2->kfp~=1.8.14)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rich>=10.11.0 (from typer<1.0,>=0.3.2->kfp~=1.8.14)\n",
      "  Downloading rich-13.9.4-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 (from httplib2<1dev,>=0.15.0->google-api-python-client<2,>=1.7.8->kfp~=1.8.14)\n",
      "  Downloading pyparsing-3.2.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.1->kfp~=1.8.14)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp~=1.8.14) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->kfp~=1.8.14) (3.10)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->typer<1.0,>=0.3.2->kfp~=1.8.14)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/hypponen/projects/softala/softala-env/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0,>=0.3.2->kfp~=1.8.14) (2.19.1)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib->kubernetes<26,>=8.0.0->kfp~=1.8.14)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.3.2->kfp~=1.8.14)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m126.5/126.5 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\u001b[36m-:--:--\u001b[0m\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading docstring_parser-0.16-py3-none-any.whl (36 kB)\n",
      "Downloading google_api_core-2.24.1-py3-none-any.whl (160 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m160.1/160.1 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m62.1/62.1 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "[?25hDownloading google_auth-2.38.0-py2.py3-none-any.whl (210 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m210.8/210.8 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "Downloading google_cloud_storage-2.19.0-py2.py3-none-any.whl (131 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl (19 kB)\n",
      "Downloading kubernetes-25.3.0-py2.py3-none-any.whl (1.4 MB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0ma \u001b[36m-:--:--\u001b[0m\n",
      "25hDownloading protobuf-3.20.3-py2.py3-none-any.whl (162 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "Downloading pydantic-1.10.21-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0ma \u001b[36m-:--:--\u001b[0m\n",
      "25hDownloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "[?25hDownloading strip_hints-0.1.13-py3-none-any.whl (23 kB)\n",
      "Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "[?25hDownloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m144.2/144.2 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading google_auth_httplib2-0.2.0-py2.py3-none-any.whl (9.3 kB)\n",
      "Downloading google_cloud_core-2.4.2-py2.py3-none-any.whl (29 kB)\n",
      "Downloading google_crc32c-1.6.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (32 kB)\n",
      "Downloading google_resumable_media-2.7.2-py2.py3-none-any.whl (81 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "[?25hDownloading googleapis_common_protos-1.68.0-py2.py3-none-any.whl (164 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m165.0/165.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m96.9/96.9 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "[?25hDownloading proto_plus-1.26.0-py3-none-any.whl (50 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "[?25hDownloading pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "Downloading rich-13.9.4-py3-none-any.whl (242 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m242.4/242.4 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m89.2/89.2 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "[?25hDownloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m72.5/72.5 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "[?25hDownloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "[?25hDownloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m83.1/83.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "[?25hDownloading pyparsing-3.2.1-py3-none-any.whl (107 kB)\n",
      "━━━━━━━━━━━\u001b[0m \u001b[32m107.7/107.7 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Building wheels for collected packages: kfp, fire, kfp-server-api\n",
      "  Building wheel for kfp (pyproject.toml): started\n",
      "  Building wheel for kfp (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for kfp: filename=kfp-1.8.22-py3-none-any.whl size=427024 sha256=5ab7d568eac1cd66a6d13fb34f088697f3f73419181f16a35b9fb490ac444fcd\n",
      "  Stored in directory: /home/hypponen/.cache/pip/wheels/90/25/79/bdab6dbacfe5c347bcddd6897d8a8fcccda743c84bc106bd43\n",
      "  Building wheel for fire (pyproject.toml): started\n",
      "  Building wheel for fire (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for fire: filename=fire-0.7.0-py3-none-any.whl size=114298 sha256=bfa9543e4f37c0a851677f652c06c9bdf33c6f7c0fa2d1b4c0bd214e4e684aef\n",
      "  Stored in directory: /home/hypponen/.cache/pip/wheels/9e/5b/45/29f72e55d87a29426b04b3cfdf20325c079eb97ab74f59017d\n",
      "  Building wheel for kfp-server-api (pyproject.toml): started\n",
      "  Building wheel for kfp-server-api (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.5-py3-none-any.whl size=99744 sha256=343b9bd09ac889a7a93d760b01d7b02226db17f0257af1f999730720bda52e75\n",
      "nen/.cache/pip/wheels/0c/bf/ac/6eef79c64b59ef39d1dcab883416022628935c25db5723cd36\n",
      "Successfully built kfp fire kfp-server-api\n",
      "Installing collected packages: wrapt, wheel, urllib3, uritemplate, termcolor, tabulate, shellingham, pyparsing, pydantic, pyasn1, protobuf, oauthlib, mdurl, google-crc32c, docstring-parser, cloudpickle, click, cachetools, absl-py, strip-hints, rsa, pyasn1-modules, proto-plus, markdown-it-py, kfp-server-api, kfp-pipeline-spec, httplib2, googleapis-common-protos, google-resumable-media, fire, Deprecated, rich, requests-toolbelt, requests-oauthlib, google-auth, typer, kubernetes, google-auth-httplib2, google-api-core, google-cloud-core, google-api-python-client, google-cloud-storage, kfp\n",
      "  Attempting uninstall: urllib3\n",
      "    Found existing installation: urllib3 2.3.0\n",
      "    Uninstalling urllib3-2.3.0:\n",
      "      Successfully uninstalled urllib3-2.3.0\n",
      "Successfully installed Deprecated-1.2.18 absl-py-1.4.0 cachetools-5.5.2 click-8.1.8 cloudpickle-2.2.1 docstring-parser-0.16 fire-0.7.0 google-api-core-2.24.1 google-api-python-client-1.12.11 google-auth-2.38.0 google-auth-httplib2-0.2.0 google-cloud-core-2.4.2 google-cloud-storage-2.19.0 google-crc32c-1.6.0 google-resumable-media-2.7.2 googleapis-common-protos-1.68.0 httplib2-0.22.0 kfp-1.8.22 kfp-pipeline-spec-0.1.16 kfp-server-api-1.8.5 kubernetes-25.3.0 markdown-it-py-3.0.0 mdurl-0.1.2 oauthlib-3.2.2 proto-plus-1.26.0 protobuf-3.20.3 pyasn1-0.6.1 pyasn1-modules-0.4.1 pydantic-1.10.21 pyparsing-3.2.1 requests-oauthlib-2.0.0 requests-toolbelt-0.10.1 rich-13.9.4 rsa-4.9 shellingham-1.5.4 strip-hints-0.1.13 tabulate-0.9.0 termcolor-2.5.0 typer-0.15.1 uritemplate-3.0.1 urllib3-1.26.20 wheel-0.45.1 wrapt-1.17.2\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "pip install kfp~=1.8.14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import kfp\n",
    "import kfp.dsl as dsl\n",
    "from kfp.aws import use_aws_secret\n",
    "from kfp.v2.dsl import (\n",
    "    component,\n",
    "    Input,\n",
    "    Output,\n",
    "    Dataset,\n",
    "    Metrics,\n",
    "    Artifact,\n",
    "    Model\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. Connect to client\n",
    "\n",
    "Run the following to port-forward to the KFP UI:\n",
    "\n",
    "```sh\n",
    "kubectl port-forward svc/ml-pipeline-ui -n kubeflow 8080:80\n",
    "```\n",
    "\n",
    "Now the KFP UI should be reachable at [`http://localhost:8080`](http://localhost:8080)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import kfp\n",
    "\n",
    "KFP_ENDPOINT = \"http://localhost:8080\"\n",
    "\n",
    "client = kfp.Client(host=KFP_ENDPOINT)\n",
    "# print(client.list_experiments())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2. Components\n",
    "\n",
    "There are different ways to define components in KFP. Here, we use the **@component** decorator to define the components as Python function-based components.\n",
    "\n",
    "The **@component** annotation converts the function into a factory function that creates pipeline steps that execute this function. This example also specifies the base container image to run you component in."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Pull data component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\"numpy~=1.26.4\", \"pandas~=1.4.2\"],\n",
    "    output_component_file='components/pull_data_component.yaml',\n",
    ")\n",
    "def pull_data(url: str, data: Output[Dataset]):\n",
    "    \"\"\"\n",
    "    Pull data component.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "\n",
    "    df = pd.read_csv(url, sep=\";\")\n",
    "    df.to_csv(data.path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Preprocess component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\"numpy~=1.26.4\", \"pandas~=1.4.2\", \"scikit-learn~=1.0.2\"],\n",
    "    output_component_file='components/preprocess_component.yaml',\n",
    ")\n",
    "def preprocess(\n",
    "    data: Input[Dataset],\n",
    "    scaler_out: Output[Artifact],\n",
    "    train_set: Output[Dataset],\n",
    "    test_set: Output[Dataset],\n",
    "    target: str = \"quality\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Preprocess component.\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    import pickle\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "    data = pd.read_csv(data.path)\n",
    "\n",
    "    # Split the data into training and test sets. (0.75, 0.25) split.\n",
    "    train, test = train_test_split(data)\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    train[train.drop(target, axis=1).columns] = scaler.fit_transform(train.drop(target, axis=1))\n",
    "    test[test.drop(target, axis=1).columns] = scaler.transform(test.drop(target, axis=1))\n",
    "\n",
    "    with open(scaler_out.path, 'wb') as fp:\n",
    "        pickle.dump(scaler, fp, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    train.to_csv(train_set.path, index=None)\n",
    "    test.to_csv(test_set.path, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Train component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "@component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\"numpy~=1.26.4\", \"pandas~=1.4.2\", \"scikit-learn~=1.0.2\", \"mlflow~=2.4.1\", \"boto3~=1.21.0\"],\n",
    "    output_component_file='components/train_component.yaml',\n",
    ")\n",
    "def train(\n",
    "    train_set: Input[Dataset],\n",
    "    test_set: Input[Dataset],\n",
    "    saved_model: Output[Model],\n",
    "    mlflow_experiment_name: str,\n",
    "    mlflow_tracking_uri: str,\n",
    "    mlflow_s3_endpoint_url: str,\n",
    "    model_name: str,\n",
    "    alpha: float,\n",
    "    l1_ratio: float,\n",
    "    target: str = \"quality\",\n",
    ") -> NamedTuple(\"Output\", [('storage_uri', str), ('run_id', str),]):\n",
    "    \"\"\"\n",
    "    Train component.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from sklearn.linear_model import ElasticNet\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    import mlflow\n",
    "    import mlflow.sklearn\n",
    "    import os\n",
    "    import logging\n",
    "    import pickle\n",
    "    from collections import namedtuple\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    def eval_metrics(actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2\n",
    "\n",
    "    os.environ['MLFLOW_S3_ENDPOINT_URL'] = mlflow_s3_endpoint_url\n",
    "\n",
    "    # load data\n",
    "    train = pd.read_csv(train_set.path)\n",
    "    test = pd.read_csv(test_set.path)\n",
    "\n",
    "    # The predicted column is \"quality\" which is a scalar from [3, 9]\n",
    "    train_x = train.drop([target], axis=1)\n",
    "    test_x = test.drop([target], axis=1)\n",
    "    train_y = train[[target]]\n",
    "    test_y = test[[target]]\n",
    "\n",
    "    logger.info(f\"Using MLflow tracking URI: {mlflow_tracking_uri}\")\n",
    "    mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "\n",
    "    logger.info(f\"Using MLflow experiment: {mlflow_experiment_name}\")\n",
    "    mlflow.set_experiment(mlflow_experiment_name)\n",
    "\n",
    "    with mlflow.start_run() as run:\n",
    "\n",
    "        run_id = run.info.run_id\n",
    "        logger.info(f\"Run ID: {run_id}\")\n",
    "\n",
    "        model = ElasticNet(alpha=alpha, l1_ratio=l1_ratio, random_state=42)\n",
    "\n",
    "        logger.info(\"Fitting model...\")\n",
    "        model.fit(train_x, train_y)\n",
    "\n",
    "        logger.info(\"Predicting...\")\n",
    "        predicted_qualities = model.predict(test_x)\n",
    "\n",
    "        (rmse, mae, r2) = eval_metrics(test_y, predicted_qualities)\n",
    "\n",
    "        logger.info(\"Elasticnet model (alpha=%f, l1_ratio=%f):\" % (alpha, l1_ratio))\n",
    "        logger.info(\"  RMSE: %s\" % rmse)\n",
    "        logger.info(\"  MAE: %s\" % mae)\n",
    "        logger.info(\"  R2: %s\" % r2)\n",
    "\n",
    "        logger.info(\"Logging parameters to MLflow\")\n",
    "        mlflow.log_param(\"alpha\", alpha)\n",
    "        mlflow.log_param(\"l1_ratio\", l1_ratio)\n",
    "        mlflow.log_metric(\"rmse\", rmse)\n",
    "        mlflow.log_metric(\"r2\", r2)\n",
    "        mlflow.log_metric(\"mae\", mae)\n",
    "\n",
    "        # save model to mlflow\n",
    "        logger.info(\"Logging trained model\")\n",
    "        mlflow.sklearn.log_model(\n",
    "            model,\n",
    "            model_name,\n",
    "            registered_model_name=\"ElasticnetWineModel\",\n",
    "            serialization_format=\"pickle\"\n",
    "        )\n",
    "\n",
    "        logger.info(\"Logging predictions artifact to MLflow\")\n",
    "        np.save(\"predictions.npy\", predicted_qualities)\n",
    "        mlflow.log_artifact(\n",
    "        local_path=\"predictions.npy\", artifact_path=\"predicted_qualities/\"\n",
    "        )\n",
    "\n",
    "        # save model as KFP artifact\n",
    "        logging.info(f\"Saving model to: {saved_model.path}\")\n",
    "        with open(saved_model.path, 'wb') as fp:\n",
    "            pickle.dump(model, fp, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "        # prepare output\n",
    "        output = namedtuple('Output', ['storage_uri', 'run_id'])\n",
    "\n",
    "        # return str(mlflow.get_artifact_uri())\n",
    "        return output(mlflow.get_artifact_uri(), run_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Evaluate component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.10\",\n",
    "    packages_to_install=[\"numpy\", \"mlflow~=2.4.1\"],\n",
    "    output_component_file='components/evaluate_component.yaml',\n",
    ")\n",
    "def evaluate(\n",
    "    run_id: str,\n",
    "    mlflow_tracking_uri: str,\n",
    "    threshold_metrics: dict\n",
    ") -> bool:\n",
    "    \"\"\"\n",
    "    Evaluate component: Compares metrics from training with given thresholds.\n",
    "\n",
    "    Args:\n",
    "        run_id (string):  MLflow run ID\n",
    "        mlflow_tracking_uri (string): MLflow tracking URI\n",
    "        threshold_metrics (dict): Minimum threshold values for each metric\n",
    "    Returns:\n",
    "        Bool indicating whether evaluation passed or failed.\n",
    "    \"\"\"\n",
    "    from mlflow.tracking import MlflowClient\n",
    "    import logging\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    client = MlflowClient(tracking_uri=mlflow_tracking_uri)\n",
    "    info = client.get_run(run_id)\n",
    "    training_metrics = info.data.metrics\n",
    "\n",
    "    logger.info(f\"Training metrics: {training_metrics}\")\n",
    "\n",
    "    # compare the evaluation metrics with the defined thresholds\n",
    "    for key, value in threshold_metrics.items():\n",
    "        if key not in training_metrics or training_metrics[key] > value:\n",
    "            logger.error(f\"Metric {key} failed. Evaluation not passed!\")\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Deploy model component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9\",\n",
    "    packages_to_install=[\"kserve==0.11.0\"],\n",
    "    output_component_file='components/deploy_model_component.yaml',\n",
    ")\n",
    "def deploy_model(model_name: str, storage_uri: str):\n",
    "    \"\"\"\n",
    "    Deploy the model as an inference service with Kserve.\n",
    "    \"\"\"\n",
    "    import logging\n",
    "    from kubernetes import client\n",
    "    from kserve import KServeClient\n",
    "    from kserve import constants\n",
    "    from kserve import V1beta1InferenceService\n",
    "    from kserve import V1beta1InferenceServiceSpec\n",
    "    from kserve import V1beta1PredictorSpec\n",
    "    from kserve import V1beta1SKLearnSpec\n",
    "    from kubernetes.client import V1ResourceRequirements\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    model_uri = f\"{storage_uri}/{model_name}\"\n",
    "    logger.info(f\"MODEL URI: {model_uri}\")\n",
    "\n",
    "    namespace = 'kserve-inference'\n",
    "    kserve_version='v1beta1'\n",
    "    api_version = constants.KSERVE_GROUP + '/' + kserve_version\n",
    "\n",
    "    isvc = V1beta1InferenceService(\n",
    "        api_version = api_version,\n",
    "        kind = constants.KSERVE_KIND,\n",
    "        metadata = client.V1ObjectMeta(\n",
    "            name = model_name,\n",
    "            namespace = namespace,\n",
    "            annotations = {'sidecar.istio.io/inject':'false'}\n",
    "        ),\n",
    "        spec = V1beta1InferenceServiceSpec(\n",
    "            predictor=V1beta1PredictorSpec(\n",
    "                service_account_name=\"kserve-sa\",\n",
    "                min_replicas=1,\n",
    "                max_replicas = 1,\n",
    "                sklearn=V1beta1SKLearnSpec(\n",
    "                    storage_uri=model_uri,\n",
    "                    resources=V1ResourceRequirements(\n",
    "                        requests={\"cpu\": \"100m\", \"memory\": \"512Mi\"},\n",
    "                        limits={\"cpu\": \"300m\", \"memory\": \"512Mi\"}\n",
    "                    )\n",
    "                ),\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "    KServe = KServeClient()\n",
    "    KServe.create(isvc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Inference component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@component(\n",
    "    base_image=\"python:3.9\",  # kserve on python 3.10 comes with a dependency that fails to get installed\n",
    "    packages_to_install=[\"kserve==0.11.0\", \"scikit-learn~=1.0.2\"],\n",
    "    output_component_file='components/inference_component.yaml',\n",
    ")\n",
    "def inference(\n",
    "    model_name: str,\n",
    "    scaler_in: Input[Artifact]\n",
    "):\n",
    "    \"\"\"\n",
    "    Test inference.\n",
    "    \"\"\"\n",
    "    from kserve import KServeClient\n",
    "    import requests\n",
    "    import pickle\n",
    "    import logging\n",
    "\n",
    "    logging.basicConfig(level=logging.INFO)\n",
    "    logger = logging.getLogger(__name__)\n",
    "\n",
    "    namespace = 'kserve-inference'\n",
    "    \n",
    "    input_sample = [[5.6, 0.54, 0.04, 1.7, 0.049, 5, 13, 0.9942, 3.72, 0.58, 11.4],\n",
    "                    [11.3, 0.34, 0.45, 2, 0.082, 6, 15, 0.9988, 2.94, 0.66, 9.2]]\n",
    "\n",
    "    logger.info(f\"Loading standard scaler from: {scaler_in.path}\")\n",
    "    with open(scaler_in.path, 'rb') as fp:\n",
    "        scaler = pickle.load(fp)\n",
    "\n",
    "    logger.info(f\"Standardizing sample: {scaler_in.path}\")\n",
    "    input_sample = scaler.transform(input_sample)\n",
    "\n",
    "    # get inference service\n",
    "    KServe = KServeClient()\n",
    "\n",
    "    # wait for deployment to be ready\n",
    "    KServe.get(model_name, namespace=namespace, watch=True, timeout_seconds=120)\n",
    "\n",
    "    inference_service = KServe.get(model_name, namespace=namespace)\n",
    "    header = {\"Host\": f\"{model_name}.{namespace}.example.com\"}\n",
    "    is_url = f\"http://istio-ingressgateway.istio-system.svc.cluster.local:80/v1/models/{model_name}:predict\"\n",
    "    \n",
    "    logger.info(f\"\\nInference service status:\\n{inference_service['status']}\")\n",
    "    logger.info(f\"\\nInference service URL:\\n{is_url}\\n\")\n",
    "\n",
    "    inference_input = {\n",
    "        'instances': input_sample.tolist()\n",
    "    }\n",
    "    response = requests.post(\n",
    "        is_url,\n",
    "        json=inference_input,\n",
    "        headers=header,\n",
    "    )\n",
    "    if response.status_code != 200:\n",
    "        raise RuntimeError(f\"HTTP status code '{response.status_code}': {response.json()}\")\n",
    "    \n",
    "    logger.info(f\"\\nPrediction response:\\n{response.json()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 3. Pipeline\n",
    "\n",
    "Pipeline definition:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "@dsl.pipeline(\n",
    "      name='demo-pipeline',\n",
    "      description='An example pipeline that performs addition calculations.',\n",
    ")\n",
    "def pipeline(\n",
    "    url: str,\n",
    "    target: str,\n",
    "    mlflow_experiment_name: str,\n",
    "    mlflow_tracking_uri: str,\n",
    "    mlflow_s3_endpoint_url: str,\n",
    "    model_name: str,\n",
    "    alpha: float,\n",
    "    l1_ratio: float,\n",
    "    threshold_metrics: dict,\n",
    "):\n",
    "    pull_task = pull_data(url=url)\n",
    "\n",
    "    preprocess_task = preprocess(data=pull_task.outputs[\"data\"])\n",
    "\n",
    "    train_task = train(\n",
    "        train_set=preprocess_task.outputs[\"train_set\"],\n",
    "        test_set=preprocess_task.outputs[\"test_set\"],\n",
    "        target=target,\n",
    "        mlflow_experiment_name=mlflow_experiment_name,\n",
    "        mlflow_tracking_uri=mlflow_tracking_uri,\n",
    "        mlflow_s3_endpoint_url=mlflow_s3_endpoint_url,\n",
    "        model_name=model_name,\n",
    "        alpha=alpha,\n",
    "        l1_ratio=l1_ratio\n",
    "    )\n",
    "    train_task.apply(use_aws_secret(secret_name=\"aws-secret\"))\n",
    "\n",
    "    evaluate_trask = evaluate(\n",
    "        run_id=train_task.outputs[\"run_id\"],\n",
    "        mlflow_tracking_uri=mlflow_tracking_uri,\n",
    "        threshold_metrics=threshold_metrics\n",
    "    )\n",
    "\n",
    "    eval_passed = evaluate_trask.output\n",
    "\n",
    "    with dsl.Condition(eval_passed == \"true\"):\n",
    "        deploy_model_task = deploy_model(\n",
    "            model_name=model_name,\n",
    "            storage_uri=train_task.outputs[\"storage_uri\"],\n",
    "        )\n",
    "\n",
    "        inference_task = inference(\n",
    "            model_name=model_name,\n",
    "            scaler_in=preprocess_task.outputs[\"scaler_out\"]\n",
    "        )\n",
    "        inference_task.after(deploy_model_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Pipeline arguments:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Specify pipeline argument values\n",
    "\n",
    "eval_threshold_metrics = {'rmse': 0.9, 'r2': 0.3, 'mae': 0.8}\n",
    "\n",
    "arguments = {\n",
    "    \"url\": \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\",\n",
    "    \"target\": \"quality\",\n",
    "    \"mlflow_tracking_uri\": \"http://mlflow.mlflow.svc.cluster.local:5000\",\n",
    "    \"mlflow_s3_endpoint_url\": \"http://mlflow-minio-service.mlflow.svc.cluster.local:9000\",\n",
    "    \"mlflow_experiment_name\": \"demo-notebook\",\n",
    "    \"model_name\": \"wine-quality\",\n",
    "    \"alpha\": 0.5,\n",
    "    \"l1_ratio\": 0.5,\n",
    "    \"threshold_metrics\": eval_threshold_metrics\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4. Submit run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:8080/#/experiments/details/5d45a0fa-ef4c-4f48-aa6b-71219ee04bf1\" target=\"_blank\" >Experiment details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://localhost:8080/#/runs/details/c5728692-2488-4a11-b4a9-e5d53ec7b62b\" target=\"_blank\" >Run details</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RunPipelineResult(run_id=c5728692-2488-4a11-b4a9-e5d53ec7b62b)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run_name = \"demo-run\"\n",
    "experiment_name = \"demo-experiment\"\n",
    "\n",
    "client.create_run_from_pipeline_func(\n",
    "    pipeline_func=pipeline,\n",
    "    run_name=run_name,\n",
    "    experiment_name=experiment_name,\n",
    "    arguments=arguments,\n",
    "    mode=kfp.dsl.PipelineExecutionMode.V2_COMPATIBLE,\n",
    "    enable_caching=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 5. Check run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Kubeflow Pipelines UI\n",
    "\n",
    "The default way of accessing KFP UI is via port-forward. This enables you to get started quickly without imposing any requirements on your environment. Run the following to port-forward KFP UI to local port `8080`:\n",
    "\n",
    "```sh\n",
    "kubectl port-forward svc/ml-pipeline-ui -n kubeflow 8080:80\n",
    "```\n",
    "\n",
    "Now the KFP UI should be reachable at [`http://localhost:8080`](http://localhost:8080)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### MLFlow UI\n",
    "\n",
    "To access MLFlow UI, open a terminal and forward a local port to MLFlow server:\n",
    "\n",
    "<br>\n",
    "\n",
    "```bash\n",
    "$ kubectl -n mlflow port-forward svc/mlflow 5000:5000\n",
    "```\n",
    "\n",
    "<br>\n",
    "\n",
    "Now MLFlow's UI should be reachable at [`http://localhost:5000`](http://localhost:5000)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 6. Check deployed model\n",
    "\n",
    "```bash\n",
    "# get inference services\n",
    "kubectl -n kserve-inference get inferenceservice\n",
    "\n",
    "# get deployed model pods\n",
    "kubectl -n kserve-inference get pods\n",
    "\n",
    "# delete inference service\n",
    "kubectl -n kserve-inference delete inferenceservice wine-quality\n",
    "```\n",
    "<br>\n",
    "\n",
    "If something goes wrong, check the logs with:\n",
    "\n",
    "<br>\n",
    "\n",
    "```bash\n",
    "kubectl logs -n kserve-inference <pod-name> kserve-container\n",
    "\n",
    "kubectl logs -n kserve-inference <pod-name> queue-proxy\n",
    "\n",
    "kubectl logs -n kserve-inference <pod-name> storage-initializer\n",
    "```\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
